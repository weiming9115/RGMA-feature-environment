{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6443480e-5d27-450a-a38d-acef0346d1db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import cartopy.crs as ccrs\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97bf18c2-42f6-4bde-8736-550e40505e6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38357691-9a9a-40e0-8605-834e4ce1095d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LPS_dir = Path('/neelin2020/RGMA_feature_mask/LPS_ERA5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c85c791-c8e0-4423-b19f-88d9e2b49e81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 42s, sys: 1.43 s, total: 11min 44s\n",
      "Wall time: 11min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#LPS_file = open(LPS_dir / 'Moist_LPS.dat', mode='r')\n",
    "var_list = ['x grid point of the centre','y grid point of the centre','longitude','latitude',\n",
    "           'minimum stream function','slp','Pressure drop','Maximum Surface Wind',\n",
    "           'Averaged relative humidity','Maximum surface geopotential','land sea ratio of the grid at the centre',\n",
    "           'ACEPSL','ACE','PDI','IKE','year','month','day','hour']\n",
    "df_list = []\n",
    "with open(LPS_dir / 'Moist_LPS.dat', 'r') as f:\n",
    "    \n",
    "    lines = f.readlines()\n",
    "    \n",
    "    for n,line in enumerate(lines):\n",
    "\n",
    "        line_current = line.split()\n",
    "        if n <= (len(lines)-2): # (n-1) n means total line number\n",
    "            line_next = lines[n+1].split()\n",
    "\n",
    "        if line_current[0] == 'start': # if a new track starts, showing a header info only\n",
    "            df_track = pd.DataFrame() # reset dataframe for a new track\n",
    "            \n",
    "        else:  # expanding the info of the current track\n",
    "            tmp = pd.DataFrame(data=np.asarray(line_current).reshape(1,19), columns=var_list)\n",
    "            df_track = pd.concat([df_track, tmp])\n",
    "\n",
    "        # end of current track\n",
    "        if line_next[0] == 'start': \n",
    "            \n",
    "            # save df_track into the list as a xarray.dataset\n",
    "            timestamp_list = []\n",
    "            lon_list = []\n",
    "            lat_list = []\n",
    "            sp_list = []\n",
    "            for t in range(len(df_track['year'])):\n",
    "                year = int(df_track.iloc[t].year)\n",
    "                month = int(df_track.iloc[t].month)\n",
    "                day = int(df_track.iloc[t].day)\n",
    "                hour = int(df_track.iloc[t].hour)\n",
    "                timestamp = datetime(year, month, day, hour)\n",
    "                timestamp_list.append(timestamp)\n",
    "                \n",
    "                lon_list.append(float(df_track.iloc[t].longitude))\n",
    "                lat_list.append(float(df_track.iloc[t].latitude))\n",
    "                sp_list.append(float(df_track.iloc[t].slp))\n",
    "            \n",
    "            # create xarray.dataset\n",
    "            ds = xr.Dataset(data_vars = dict(\n",
    "                            meanlon = (['time'], lon_list),\n",
    "                            meanlat = (['time'], lat_list),\n",
    "                            slp = (['time'], sp_list),\n",
    "                            base_time = (['time'], timestamp_list)),\n",
    "                           \n",
    "                            coords= dict(time = (['time'], range(len(timestamp_list)))),\n",
    "                            attrs = dict(description='TempestExtremes LPS tracks',\n",
    "                                         frequency='hourly',\n",
    "                                         source='ERA5, 0.25-deg.',\n",
    "                                         upper_bound='duration max. = 10 days'\n",
    "                                         ))\n",
    "            \n",
    "          # 10 days upper bound for LPS (avoid including synoptic lows lasting over 20-30 days)\n",
    "            tmp = ds.meanlon.values\n",
    "            duration = len(tmp[~np.isnan(tmp)])\n",
    "            if duration <= 240:\n",
    "                df_list.append(ds)\n",
    "\n",
    "        # for the last track\n",
    "        if n == (len(lines)-1): # the last line\n",
    "            \n",
    "            # save df_track into the list as a xarray.dataset\n",
    "            timestamp_list = []\n",
    "            lon_list = []\n",
    "            lat_list = []\n",
    "            sp_list = []\n",
    "            for t in range(len(df_track['year'])):\n",
    "                year = int(df_track.iloc[t].year)\n",
    "                month = int(df_track.iloc[t].month)\n",
    "                day = int(df_track.iloc[t].day)\n",
    "                hour = int(df_track.iloc[t].hour)\n",
    "                timestamp = datetime(year, month, day, hour)\n",
    "                timestamp_list.append(timestamp)\n",
    "                \n",
    "                lon_list.append(float(df_track.iloc[t].longitude))\n",
    "                lat_list.append(float(df_track.iloc[t].latitude))\n",
    "                sp_list.append(float(df_track.iloc[t].slp))                \n",
    "            \n",
    "            # create xarray.dataset\n",
    "            ds = xr.Dataset(data_vars = dict(\n",
    "                            meanlon = (['time'], lon_list),\n",
    "                            meanlat = (['time'], lat_list),\n",
    "                            slp = (['time'], sp_list),\n",
    "                            base_time = (['time'], timestamp_list)),\n",
    "                           \n",
    "                            coords= dict(time = (['time'], range(len(timestamp_list)))),\n",
    "                            attrs = dict(description='TempestExtremes LPS tracks',\n",
    "                                         frequency='hourly',\n",
    "                                         source='ERA5, 0.25-deg.',\n",
    "                                         upper_bound='duration max. = 10 days'\n",
    "                                         ))\n",
    "            \n",
    "            \n",
    "            # 10 days upper bound for LPS (avoid including synoptic lows lasting over 20-30 days)\n",
    "            tmp = ds.meanlon.values\n",
    "            duration = len(tmp[~np.isnan(tmp)])\n",
    "            if duration <= 240:\n",
    "                df_list.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54952b34-5038-4a2b-a7ac-8ff53187378f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge all tracks into a single xarray.dataset file \n",
    "ds_LPS = xr.concat(df_list, dim=pd.Index(np.arange(len(df_list)), name='tracks'))\n",
    "\n",
    "# extract 2000-2020 to match existing EAR5 data\n",
    "idx_year = np.asarray([str(i)[:4] for i in ds_LPS.base_time.isel(time=0).values], dtype='int')\n",
    "idx_select = np.where(np.logical_and(idx_year >= 2001, idx_year <= 2020))[0]\n",
    "ds_LPS_20yr = ds_LPS.isel(tracks=idx_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af4df463-1958-4723-ad79-b85590a4269a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx_select = np.where(idx_year == 2014)[0]\n",
    "ds_LPS_2014 = ds_LPS.isel(tracks=idx_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d8cf295-b6d0-48e9-bfab-2fe1d620ef74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_LPS_20yr.to_netcdf('/neelin2020/RGMA_feature_mask/LPS_ERA5/ERA5_LPS_tracks_2001_2020.nc'\n",
    "                     , encoding={'meanlon': {'dtype': 'float32'}, 'meanlat': {'dtype': 'float32'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ca9157b-eca1-47fa-9d89-2069552a41da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_LPS_2014.to_netcdf('/neelin2020/RGMA_feature_mask/LPS_ERA5/ERA5_LPS_tracks_2014.nc'\n",
    "                     , encoding={'meanlon': {'dtype': 'float32'}, 'meanlat': {'dtype': 'float32'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f75617b6-bd87-492c-95f1-ef33ac314be2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx_select = np.where(idx_year == 2015)[0]\n",
    "ds_LPS_2015 = ds_LPS.isel(tracks=idx_select)\n",
    "ds_LPS_2015.to_netcdf('/neelin2020/RGMA_feature_mask/LPS_ERA5/ERA5_LPS_tracks_2015.nc'\n",
    "                     , encoding={'meanlon': {'dtype': 'float32'}, 'meanlat': {'dtype': 'float32'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976fa16a-4ea7-427f-a446-ab3aac3f5fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = np.arange(2001,2021)\n",
    "for year in year_list:\n",
    "    idx_select = np.where(idx_year == year)[0]\n",
    "    ds_LPS_year = ds_LPS.isel(tracks=idx_select)\n",
    "    ds_LPS_year.to_netcdf('/neelin2020/RGMA_feature_mask/LPS_ERA5/ERA5_LPS_tracks_{}.nc'.format(year)\n",
    "                     , encoding={'meanlon': {'dtype': 'float32'}, 'meanlat': {'dtype': 'float32'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c83712b-7981-49b8-a569-270ec4959464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854bb5d4-6911-4dee-bb59-2fc5a61205d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2086c92-92f2-4403-ae76-20d1d73bdcdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_kernel",
   "language": "python",
   "name": "base_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
